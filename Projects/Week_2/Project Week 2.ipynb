{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libriries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data set\n",
    "df = pd.read_csv('/Users/joaootaviomeirellesratton/Desktop/Ironhack/Labs_mycodes/Projects/Week_2/attacks.csv', sep=(','), encoding=('latin-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number         Date    Year        Type    Country             Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating        USA       California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA          Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid        USA           Hawaii   \n",
       "3  2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "4  2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO           Colima   \n",
       "\n",
       "                         Location     Activity             Name Sex   ...  \\\n",
       "0     Oceanside, San Diego County     Paddling      Julie Wolfe    F  ...   \n",
       "1  St. Simon Island, Glynn County     Standing  Adyson McNeely     F  ...   \n",
       "2                    Habush, Oahu      Surfing      John Denges    M  ...   \n",
       "3              Arrawarra Headland      Surfing             male    M  ...   \n",
       "4                        La Ticla  Free diving   Gustavo Ramos     M  ...   \n",
       "\n",
       "          Species           Investigator or Source                       pdf  \\\n",
       "0      White shark                R. Collier, GSAF      2018.06.25-Wolfe.pdf   \n",
       "1              NaN  K.McMurray, TrackingSharks.com    2018.06.18-McNeely.pdf   \n",
       "2              NaN  K.McMurray, TrackingSharks.com     2018.06.09-Denges.pdf   \n",
       "3        2 m shark                  B. Myatt, GSAF  2018.06.08-Arrawarra.pdf   \n",
       "4  Tiger shark, 3m                       A .Kipper      2018.06.04-Ramos.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "\n",
       "  Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0    2018.06.25         6303.0         NaN         NaN  \n",
       "1    2018.06.18         6302.0         NaN         NaN  \n",
       "2    2018.06.09         6301.0         NaN         NaN  \n",
       "3    2018.06.08         6300.0         NaN         NaN  \n",
       "4    2018.06.04         6299.0         NaN         NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking data set\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping entire rows with null values above 85%\n",
    "\n",
    "df.drop(df[df.isnull().mean(axis=1) >= 0.85].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 'Year' Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming values to int and classifying nan\n",
    "df['Year'] = df['Year'].apply(lambda x: int(x) if x > 0 else 'N/A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 'Country' Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing blanks\n",
    "df['Country']= df['Country'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                       35.65%\n",
       "AUSTRALIA                  21.4%\n",
       "SOUTH AFRICA               9.26%\n",
       "PAPUA NEW GUINEA           2.14%\n",
       "NEW ZEALAND                2.05%\n",
       "                           ...  \n",
       "RED SEA / INDIAN OCEAN     0.02%\n",
       "ST. MARTIN                 0.02%\n",
       "MID-PACIFC OCEAN           0.02%\n",
       "MALDIVE ISLANDS            0.02%\n",
       "NORTH SEA                  0.02%\n",
       "Name: Country, Length: 204, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking countries with the most shark attack records\n",
    "country_share = df['Country'].value_counts(normalize=True).sort_values(ascending=False).mul(100).round(2).astype('str') + '%'\n",
    "country_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array to list\n",
    "y = df['Country'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort list of countries\n",
    "z = [str(x) for x in y]\n",
    "z.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country_new'] = df['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "mask = (df['Country_new'] != 'USA') & (df['Country_new'] != 'AUSTRALIA')\n",
    "\n",
    "df['Country_new'][mask] = 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'AUSTRALIA', 'OTHER'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country_new'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 'Area' Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing nan to unknown area\n",
    "df['Area'] = df['Area'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing strings, removing blanks and setting to lower case\n",
    "df['Area'] = df['Area'].apply(lambda x: str(x).strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group of classified oceans by area\n",
    "ocean_area = {\n",
    "'north_pacific' : ['california', 'hawaii', 'oregon', 'palmyra atoll', 'johnston atoll', 'alaska', 'midway atoll', 'guam', 'wake island'],\n",
    "'north_atlantic' : ['georgia', 'florida', 'south carolina', 'new york', 'massachusetts', 'new jersey', 'washington', 'north carolina', \n",
    "    'maryland', 'delaware', 'maine', 'virginia', 'north carolina', 'rhode island', 'north & south carolina','connecticut', 'east coast'],\n",
    "'other_locations' : ['kentucky', 'new mexico', 'missouri', 'pennsylvania', 'illinois'],\n",
    "'gulf_caribean' : ['texas','alabama', 'louisiana', 'puerto rico', 'us virgin islands', 'cuba','mississipi'],\n",
    "'south_pacific': ['new south wales','queensland','victoria','south australia','tasmania','torres strait','northern territory', 'norfolk island'],\n",
    "'indian' : ['westerm australia','western australia', 'territory of cocos (keeling) islands']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ocean based on area\n",
    "def ocean_location(x):\n",
    "    for i in range(len(ocean_area)):\n",
    "        if x in list(ocean_area.values())[i]:\n",
    "            return list(ocean_area.keys())[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ocean based on area\n",
    "df['Ocean'] = df['Area'].apply(ocean_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 'Species' Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing nan to unknown species\n",
    "df['Species '] = df['Species '].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing strings, removing blanks and setting to lower case\n",
    "df['Species '] = df['Species '].apply(lambda x: str(x).strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new collumn that will contain treated strings\n",
    "df['species_treated'] = df['Species ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying species\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*white.*', 'white shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*tiger.*', 'tiger shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*bull.*', 'bull shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*lemon.*', 'lemon shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*grey.*', 'grey reef shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*tawn[e]y.*', 'tawny nurse shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*spinner.*', 'spinner shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*blacktip.*', 'blacktip shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*hammerhead.*', 'hammerhead shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*wobbegong.*', 'wobbegong shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*cookie.*', 'cookiecutter shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*seven[ -]gill.*', 'seven_gill shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*sevengill.*', 'seven_gill shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*reef.*', 'reef shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*dogfish.*', 'dogfish shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*whaler.*', 'whaler shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*mako.*', 'mako shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*nurse.*', 'nurse shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*blue.*', 'blue shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*sand.*', 'sand shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*galapagos.*', 'galapagos shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*salmon.*', 'salmon shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*cat.*', 'cat shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*raggedtooth.*', 'raggedtooth shark', x))\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: re.sub('.*carpet.*', 'carpet shark', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group of classified species\n",
    "shark_species = ['blacktip shark','blue shark','bull shark','carpet shark','cat shark',\n",
    "'cookiecutter shark','dogfish shark','grey reef shark','hammerhead shark','lemon shark',\n",
    "'mako shark','nurse shark','raggedtooth shark','reef shark','salmon shark','sand sharkgalapagos shark',\n",
    "'seven_gill shark','spinner shark','tawny nurse shark','tiger shark','whaler shark','white shark',\n",
    "'wobbegong shark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species/string not in defined grouped will be classified as n/a\n",
    "def check_species(x):\n",
    "    if x not in shark_species:\n",
    "        x = 'n/a'\n",
    "    else:\n",
    "        x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species/string not in defined grouped will be classified as n/a\n",
    "df['species_treated'] = df['species_treated'].apply(lambda x: check_species(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - Is there a difference among shark species attacks according to the ocean? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering countries (USA and Australia, together they account for over 55% of reported cases), removing invalid cases and undefined shark species\n",
    "df_analysis = df.query('(Country == \"AUSTRALIA\") | (Country == \"USA\")').query('Type != \"Invalid\"').query('species_treated != \"n/a\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Ocean</th>\n",
       "      <th>species_treated</th>\n",
       "      <th>case_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>indian</td>\n",
       "      <td>blacktip shark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>indian</td>\n",
       "      <td>blue shark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>indian</td>\n",
       "      <td>bull shark</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>indian</td>\n",
       "      <td>carpet shark</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>indian</td>\n",
       "      <td>hammerhead shark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>USA</td>\n",
       "      <td>north_pacific</td>\n",
       "      <td>tiger shark</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>USA</td>\n",
       "      <td>north_pacific</td>\n",
       "      <td>white shark</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>USA</td>\n",
       "      <td>other_locations</td>\n",
       "      <td>cat shark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>USA</td>\n",
       "      <td>other_locations</td>\n",
       "      <td>nurse shark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>USA</td>\n",
       "      <td>other_locations</td>\n",
       "      <td>tiger shark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country            Ocean   species_treated  case_count\n",
       "0   AUSTRALIA           indian    blacktip shark           1\n",
       "1   AUSTRALIA           indian        blue shark           1\n",
       "2   AUSTRALIA           indian        bull shark           3\n",
       "3   AUSTRALIA           indian      carpet shark           5\n",
       "4   AUSTRALIA           indian  hammerhead shark           1\n",
       "..        ...              ...               ...         ...\n",
       "57        USA    north_pacific       tiger shark          86\n",
       "58        USA    north_pacific       white shark         184\n",
       "59        USA  other_locations         cat shark           1\n",
       "60        USA  other_locations       nurse shark           1\n",
       "61        USA  other_locations       tiger shark           1\n",
       "\n",
       "[62 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting occurrences by Country/Ocean/Shark Species\n",
    "df_analysis.groupby(by=['Country', 'Ocean','species_treated']).agg(case_count = ('Country', 'count')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to csv\n",
    "df_analysis.to_csv('../shark_ocean_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.query('Area == \"new mexico\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://sharkattackfile.net/spreadsheets/pdf_directory/2005.03.12-Pitts.pdf']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
